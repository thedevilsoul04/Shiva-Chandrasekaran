# -*- coding: utf-8 -*-
"""credit card fraud detection using R.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ejAuVsDR2JMnIfV3WYjRIcTQAIKgHzOk
"""

install.packages("ranger")
library(ranger)
install.packages("caret")
library(caret)
library(data.table)

creditcard_data <- read.csv("/creditcard.csv")
dim(creditcard_data)
head(creditcard_data,6)

tail(creditcard_data,10)

table(creditcard_data$Class)

summary(creditcard_data$Amount)

names(creditcard_data)

var(creditcard_data$Amount)

sd(creditcard_data$Amount)

head(creditcard_data)

creditcard_data$Amount=scale(creditcard_data$Amount)
NewData=creditcard_data[,-c(1)]
head(NewData)

install.packages("caTools")
library(caTools)
set.seed(123)
data_sample = sample.split(NewData$Class,SplitRatio=0.80)
train_data = subset(NewData,data_sample==TRUE)
test_data = subset(NewData,data_sample==FALSE)
dim(train_data)
dim(test_data)

Logistic_Model=glm(Class~.,test_data,family=binomial())
summary(Logistic_Model)

plot(Logistic_Model)

install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
decisionTree_model <- rpart(Class ~ . , creditcard_data, method = 'class')
predicted_val <- predict(decisionTree_model, creditcard_data, type = 'class')
probability <- predict(decisionTree_model, creditcard_data, type = 'prob')
rpart.plot(decisionTree_model)

install.packages("neuralnet")
library(neuralnet)
ANN_model =neuralnet (Class~.,train_data,linear.output=FALSE)
plot(ANN_model)
predANN=compute(ANN_model,test_data)
resultANN=predANN$net.result
resultANN=ifelse(resultANN>0.5,1,0)

ANN_model =neuralnet (Class~.,train_data,linear.output=FALSE)
plot(ANN_model)
predANN=compute(ANN_model,test_data)
resultANN=predANN$net.result
resultANN=ifelse(resultANN>0.5,1,0)

plot(ANN_model)

install.packages("gbm")
library(gbm, quietly=TRUE)
system.time(
       model_gbm <- gbm(Class ~ .
               , distribution = "bernoulli"
               , data = rbind(train_data, test_data)
               , n.trees = 500
               , interaction.depth = 3
               , n.minobsinnode = 100
               , shrinkage = 0.01
               , bag.fraction = 0.5
               , train.fraction = nrow(train_data) / (nrow(train_data) + nrow(test_data))
)
)
gbm.iter = gbm.perf(model_gbm, method = "test")

# Check for missing values in your 'Class' variable in both train_data and test_data
print(sum(is.na(train_data$Class)))
print(sum(is.na(test_data$Class)))

# If missing values are found, you have a couple of options:

# 1. Remove rows with missing values (if the number of such rows is small)
train_data <- train_data[!is.na(train_data$Class), ]
test_data <- test_data[!is.na(test_data$Class), ]

# 2. Impute missing values with a suitable method (mean, median, mode, etc.)
# Example using mean imputation (replace with a method appropriate for your data)
train_data$Class[is.na(train_data$Class)] <- mean(train_data$Class, na.rm = TRUE)
test_data$Class[is.na(test_data$Class)] <- mean(test_data$Class, na.rm = TRUE)

# After handling missing values, rerun your gbm model training:
system.time(
       model_gbm <- gbm(Class ~ .
               , distribution = "bernoulli"
               , data = rbind(train_data, test_data)
               , n.trees = 500
               , interaction.depth = 3
               , n.minobsinnode = 100
               , shrinkage = 0.01
               , bag.fraction = 0.5
               , train.fraction = nrow(train_data) / (nrow(train_data) + nrow(test_data))
)
)

gbm.iter = gbm.perf(model_gbm, method = "test")

model.influence = relative.influence(model_gbm, n.trees = gbm.iter, sort. = TRUE)
plot(model_gbm)

install.packages("scikit-learn")
library(pROC)

gbm_test = predict(model_gbm, newdata = test_data, n.trees = gbm.iter)
gbm_auc = roc(test_data$Class, gbm_test, plot = TRUE, col = "red")

print(gbm_auc)

